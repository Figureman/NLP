{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b637d0-95ff-427f-b758-f5253eeaf8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCNN\n",
    "\n",
    "\n",
    "# coding: UTF-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextCNN_Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self, embedding):\n",
    "        self.model_name = 'TextCNN'\n",
    "        self.train_path ='data/train.txt'                                # 训练集\n",
    "        self.dev_path = 'data/dev.txt'                                    # 验证集\n",
    "        self.test_path = 'data/test.txt'                                  # 测试集\n",
    "        self.class_list = [x.strip() for x in open(\n",
    "             'data/class.txt', encoding='utf-8').readlines()]           # 类别名单\n",
    "        self.vocab_path = 'data/vocab.pkl'                                # 词表\n",
    "        self.save_path = 'data/saved_dict/' + self.model_name + '.ckpt'        # 模型训练结果\n",
    "        self.log_path = 'data/log/' + self.model_name\n",
    "        self.embedding_pretrained = torch.tensor(\n",
    "            np.load('data/' + embedding)[\"embeddings\"].astype('float32'))\\\n",
    "            if embedding != 'random' else None                                       # 预训练词向量\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n",
    "\n",
    "        self.dropout = 0.5                                              # 随机失活\n",
    "        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list)                         # 类别数\n",
    "        self.n_vocab = 0                                                # 词表大小，在运行时赋值\n",
    "        self.num_epochs = 20                                            # epoch数\n",
    "        self.batch_size = 128                                           # mini-batch大小\n",
    "        self.pad_size = 300                                              # 每句话处理成的长度(短填长切)\n",
    "        self.learning_rate = 1e-3                                       # 学习率\n",
    "        self.embed = self.embedding_pretrained.size(1)\\\n",
    "            if self.embedding_pretrained is not None else 300           # 字向量维度\n",
    "        self.filter_sizes = (2, 3, 4)                                   # 卷积核尺寸\n",
    "        self.num_filters = 256                                          # 卷积核数量(channels数)\n",
    "\n",
    "'''Convolutional Neural Networks for Sentence Classification'''\n",
    "\n",
    "\n",
    "class TextCNN_Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN_Model, self).__init__()\n",
    "        if config.embedding_pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, config.num_filters, (k, config.embed)) for k in config.filter_sizes])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(config.num_filters * len(config.filter_sizes), config.num_classes)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x[0])\n",
    "        out = out.unsqueeze(1)\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed11d96a-333e-4125-86bc-f2d0b124b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextRCNN\n",
    "\n",
    "# coding: UTF-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextRCNN_Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self, embedding):\n",
    "        self.model_name = 'TextRCNN'\n",
    "        self.train_path = \"data/train.txt\"                                # 训练集\n",
    "        self.dev_path ='data/dev.txt'                                    # 验证集\n",
    "        self.test_path ='data/test.txt'                                  # 测试集\n",
    "        self.class_list = [x.strip() for x in open(\n",
    "             'data/class.txt', encoding='utf-8').readlines()]              # 类别名单\n",
    "        self.vocab_path = 'data/vocab.pkl'                                # 词表\n",
    "        self.save_path = 'data/saved_dict/' + self.model_name + '.ckpt'        # 模型训练结果\n",
    "        self.log_path =  'data/log/' + self.model_name\n",
    "        self.embedding_pretrained = torch.tensor(\n",
    "            np.load('data/' + embedding)[\"embeddings\"].astype('float32'))\\\n",
    "            if embedding != 'random' else None                                       # 预训练词向量\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n",
    "\n",
    "        self.dropout = 1.0                                              # 随机失活\n",
    "        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list)                         # 类别数\n",
    "        self.n_vocab = 0                                                # 词表大小，在运行时赋值\n",
    "        self.num_epochs = 10                                            # epoch数\n",
    "        self.batch_size = 128                                           # mini-batch大小\n",
    "        self.pad_size = 300                                              # 每句话处理成的长度(短填长切)\n",
    "        self.learning_rate = 1e-3                                       # 学习率\n",
    "        self.embed = self.embedding_pretrained.size(1)\\\n",
    "            if self.embedding_pretrained is not None else 300           # 字向量维度, 若使用了预训练词向量，则维度统一\n",
    "        self.hidden_size = 256                                          # lstm隐藏层\n",
    "        self.num_layers = 1                                             # lstm层数\n",
    "\n",
    "\n",
    "'''Recurrent Convolutional Neural Networks for Text Classification'''\n",
    "\n",
    "\n",
    "class TextRCNN_Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextRCNN_Model, self).__init__()\n",
    "        if config.embedding_pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1)\n",
    "        self.lstm = nn.LSTM(config.embed, config.hidden_size, config.num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=config.dropout)\n",
    "        self.maxpool = nn.MaxPool1d(config.pad_size)\n",
    "        self.fc = nn.Linear(config.hidden_size * 2 + config.embed, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = x\n",
    "        embed = self.embedding(x)  # [batch_size, seq_len, embeding]=[64, 32, 64]\n",
    "        out, _ = self.lstm(embed)\n",
    "        out = torch.cat((embed, out), 2)\n",
    "        out = F.relu(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.maxpool(out).squeeze()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3233e4-f17d-4eb7-89ac-1b7acc5eb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入配置文件\n",
    "embedding = 'embedding_data.npz'\n",
    "TCNNconfig = TextCNN_Config(embedding)\n",
    "TRCNNconfig = TextRCNN_Config(embedding)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21507f26-84fe-47d6-9368-ce1f8a9dcdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#引入TextCNN模型\n",
    "CNN_model=TextCNN_Model(TCNNconfig)\n",
    "CNN_model.load_state_dict(torch.load('data/saved_dict/TextCNN.ckpt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb89baed-ec33-47d1-a1c2-1ac9410994ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.0 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#引入TextRCNN模型\n",
    "RCNN_model=TextRCNN_Model(TRCNNconfig)\n",
    "RCNN_model.load_state_dict(torch.load('data/saved_dict/TextRCNN.ckpt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf508a36-9538-4462-a04c-54c5e87dfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入测试集\n",
    "inputs=[]\n",
    "labels=[]\n",
    "with open(\"data/test.txt\", \"rb\") as f:\n",
    "    for line in f.readlines(): \n",
    "        lin = line.decode().strip()\n",
    "        List=lin.split(\"\\t\")\n",
    "        inputs.append(List[0])\n",
    "        labels.append(List[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cacf8f-643b-4992-833e-ed0b218dca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据处理\n",
    "\n",
    "MAX_VOCAB_SIZE = 10000  # 词表长度限制\n",
    "UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号\n",
    "\n",
    "\n",
    "def build_dataset(config,words):\n",
    "    tokenizer = lambda x: x.split(' ')  # 以空格隔开，word-level\n",
    "    vocab = pkl.load(open(config.vocab_path, 'rb'))\n",
    "    words=words+'\\t'+'0'\n",
    "    contents = []\n",
    "    lin = words.strip()\n",
    "    content, label = lin.split('\\t')\n",
    "    words_line = []\n",
    "    token = tokenizer(content)\n",
    "    seq_len = len(token)\n",
    "    if config.pad_size:\n",
    "        if len(token) < config.pad_size:\n",
    "            token.extend([PAD] * (config.pad_size - len(token)))\n",
    "        else:\n",
    "            token = token[:config.pad_size]\n",
    "            seq_len = config.pad_size\n",
    "    # word to id\n",
    "    for word in token:\n",
    "        words_line.append(vocab.get(word, vocab.get(UNK)))\n",
    "    contents.append((words_line, int(label), seq_len))\n",
    "    return contents\n",
    "\n",
    "class DatasetIterater(object):\n",
    "    def __init__(self, batches, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = batches\n",
    "        self.n_batches = len(batches) // batch_size\n",
    "        self.residue = False  # 记录batch数量是否为整数\n",
    "        if len(batches) % self.n_batches != 0:\n",
    "            self.residue = True\n",
    "        self.index = 0\n",
    "        self.device = device\n",
    "\n",
    "    def _to_tensor(self, datas):\n",
    "        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n",
    "        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n",
    "        # pad前的长度(超过pad_size的设为pad_size)\n",
    "        seq_len = torch.LongTensor([_[2] for _ in datas]).to(self.device)\n",
    "        return (x, seq_len), y\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.residue and self.index == self.n_batches:\n",
    "            batches = self.batches[self.index * self.batch_size: len(self.batches)]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "        elif self.index >= self.n_batches:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            batches = self.batches[self.index * self.batch_size: (self.index + 1) * self.batch_size]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.residue:\n",
    "            return self.n_batches + 1\n",
    "        else:\n",
    "            return self.n_batches\n",
    "\n",
    "def build_iterator(dataset, config):\n",
    "    iter = DatasetIterater(dataset, 1, config.device)\n",
    "    return iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cae8bb-5122-4e6b-8f1c-98daa3bb4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type=['alt.atheism',\n",
    "                'comp.graphics',\n",
    "                'comp.os.ms-windows.misc',\n",
    "                'comp.sys.ibm.pc.hardware',\n",
    "                'comp.sys.mac.hardware',\n",
    "                'comp.windows.x',\n",
    "                'misc.forsale',\n",
    "                'rec.autos',\n",
    "                'rec.motorcycles',\n",
    "                'rec.sport.baseball',\n",
    "                'rec.sport.hockey',\n",
    "                'sci.crypt',\n",
    "                'sci.electronics',\n",
    "                'sci.med',\n",
    "                'sci.space',\n",
    "                'soc.religion.christian',\n",
    "                'talk.politics.guns',\n",
    "                'talk.politics.mideast',\n",
    "                'talk.politics.misc',\n",
    "                'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b09a8169-f172-4b48-9775-ef68ddc4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def TCNNpredict( model, words,config):\n",
    "    data=build_dataset(config,words)\n",
    "    iter=build_iterator(data,config)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in iter:\n",
    "            outputs = model(texts)\n",
    "            List=outputs.tolist()\n",
    "            List1=List[0]\n",
    "            Result=List1.index(max(List1))\n",
    "            return Result\n",
    "\n",
    "def TRCNNpredict( model, words,config):\n",
    "    data=build_dataset(config,words)\n",
    "    iter=build_iterator(data,config)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in iter:\n",
    "            outputs = model(texts)\n",
    "            List=outputs.tolist()\n",
    "            Result=List.index(max(List))\n",
    "            return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05245a7-7029-483f-a98d-5b95c01894aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于测试集，我们来对每一个样本进行推理预测并计算其准确率，这里展示前十个\n",
    "def  predict(inputs,labels):\n",
    "    count=10\n",
    "    countTcnn=0\n",
    "    countTrcnn=0\n",
    "    length=len(inputs)\n",
    "    for i in range(length):\n",
    "        res1=TCNNpredict(CNN_model,inputs[i],TCNNconfig)\n",
    "        res2=TRCNNpredict(RCNN_model,inputs[i],TRCNNconfig)\n",
    "        label=labels[i]\n",
    "        if(i<=count):\n",
    "            print(\"第%d个样本中，TextCNN预测结果为%d,TextRCNN预测结果为%d,标准答案为%d\"%(i,res1,res2,int(label)))\n",
    "        if(label!=res1):countTcnn+=1\n",
    "        if(label!=res2):countTrcnn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c74977-905f-47c7-82b7-6ba92a1b6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个样本中，TextCNN预测结果为16,TextRCNN预测结果为16,标准答案为16\n",
      "第1个样本中，TextCNN预测结果为17,TextRCNN预测结果为17,标准答案为17\n",
      "第2个样本中，TextCNN预测结果为3,TextRCNN预测结果为3,标准答案为3\n",
      "第3个样本中，TextCNN预测结果为16,TextRCNN预测结果为16,标准答案为16\n",
      "第4个样本中，TextCNN预测结果为15,TextRCNN预测结果为15,标准答案为15\n",
      "第5个样本中，TextCNN预测结果为10,TextRCNN预测结果为10,标准答案为10\n",
      "第6个样本中，TextCNN预测结果为5,TextRCNN预测结果为5,标准答案为5\n",
      "第7个样本中，TextCNN预测结果为18,TextRCNN预测结果为18,标准答案为18\n",
      "第8个样本中，TextCNN预测结果为3,TextRCNN预测结果为3,标准答案为3\n",
      "第9个样本中，TextCNN预测结果为15,TextRCNN预测结果为15,标准答案为15\n",
      "第10个样本中，TextCNN预测结果为14,TextRCNN预测结果为18,标准答案为14\n",
      "0.000\n",
      "0.000\n"
     ]
    }
   ],
   "source": [
    "predict(inputs,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
